import Groq from 'groq-sdk'
import { IntentResult, IntentType } from '@/lib/types/intents'

interface ConversationMessage {
  role: string
  content: string
  created_at?: string
}

interface LLMIntentResponse {
  intent: IntentType
  confidence: number
  extracted_data?: {
    food?: string
    quantity?: string
    unit?: string
    exercise?: string
    duration?: string
    [key: string]: any
  }
  reasoning?: string
}

// Inicializar cliente Groq
function getGroqClient() {
  const apiKey = process.env.GROQ_API_KEY

  if (!apiKey) {
    console.error('‚ùå GROQ_API_KEY n√£o est√° configurada')
    return null
  }

  return new Groq({
    apiKey: apiKey,
  })
}

/**
 * Classifica inten√ß√£o usando LLM (Groq)
 * Analisa todas as mensagens do usu√°rio desde a √∫ltima resposta do assistente
 * @param messages Array de mensagens do usu√°rio desde a √∫ltima resposta
 * @param recentHistory Hist√≥rico recente da conversa (√∫ltimas 5 mensagens) para contexto
 * @returns IntentResult com intent, confidence e extracted_data
 */
export async function classifyIntentWithLLM(
  messages: ConversationMessage[],
  recentHistory?: ConversationMessage[]
): Promise<IntentResult | null> {
  try {
    const groq = getGroqClient()
    if (!groq) {
      throw new Error('Groq client not initialized')
    }

    if (!messages || messages.length === 0) {
      console.log('‚ö†Ô∏è No messages provided for LLM classification')
      return null
    }

    // Concatenar todas as mensagens do usu√°rio
    const userMessagesText = messages
      .map((msg) => msg.content)
      .join('\n')
      .trim()

    // Formatar hist√≥rico recente para contexto
    const historyText = recentHistory
      ? recentHistory
          .slice(-5) // √öltimas 5 mensagens
          .map((msg) => `${msg.role === 'user' ? 'Usu√°rio' : 'Assistente'}: ${msg.content}`)
          .join('\n')
      : 'Nenhum hist√≥rico dispon√≠vel'

    console.log('ü§ñ Classifying intent with LLM:', {
      messageCount: messages.length,
      totalLength: userMessagesText.length,
      hasHistory: !!recentHistory && recentHistory.length > 0,
    })

    const systemPrompt = `Voc√™ √© um classificador de inten√ß√µes para um bot nutricional no WhatsApp.

Analise TODAS as mensagens do usu√°rio abaixo (desde a √∫ltima resposta do bot) e identifique a inten√ß√£o principal.

Inten√ß√µes poss√≠veis:
- greeting: cumprimentos (ol√°, oi, bom dia, etc.)
- help: pedido de ajuda ou comandos
- register_meal: registrar refei√ß√£o/comida (comi, almocei, jantei, etc.)
- register_exercise: registrar exerc√≠cio (corri, malhei, treino, etc.)
- query_balance: consultar saldo de calorias restantes
- query_food_info: consultar informa√ß√µes nutricionais de um alimento
- daily_summary: resumo do dia
- summary_week: resumo da semana
- update_user_data: atualizar dados pessoais (peso, altura, idade)
- update_goal: atualizar meta de calorias/prote√≠nas
- onboarding: primeiro uso/cadastro
- unknown: n√£o identificado (use apenas se realmente n√£o conseguir identificar)

IMPORTANTE:
- Se o usu√°rio enviou m√∫ltiplas mensagens, analise TODAS juntas
- Se mencionar alimento OU quantidade, provavelmente √© register_meal ou query_food_info
- Se mencionar exerc√≠cio OU dura√ß√£o, provavelmente √© register_exercise
- Se for pergunta sobre calorias/prote√≠nas de um alimento, √© query_food_info
- Se for pergunta sobre quanto ainda pode comer, √© query_balance

Responda APENAS com JSON v√°lido, sem markdown, sem explica√ß√µes adicionais:
{
  "intent": "nome_da_intencao",
  "confidence": 0.0-1.0,
  "extracted_data": {
    "food": "nome do alimento se houver",
    "quantity": "quantidade num√©rica se houver",
    "unit": "unidade (g, kg, unidade, etc.) se houver",
    "exercise": "nome do exerc√≠cio se houver",
    "duration": "dura√ß√£o em minutos se houver"
  },
  "reasoning": "breve explica√ß√£o em uma frase"
}`

    const userPrompt = `Mensagens do usu√°rio (desde √∫ltima resposta):
${userMessagesText}

Hist√≥rico recente (√∫ltimas 5 mensagens):
${historyText}

Classifique a inten√ß√£o e extraia dados relevantes.`

    const timeout = parseInt(process.env.LLM_INTENT_TIMEOUT_MS || '3000', 10)

    // Criar promise com timeout
    const classificationPromise = groq.chat.completions.create({
      model: 'llama-3.1-8b-instant',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt },
      ],
      max_tokens: 300,
      temperature: 0.3, // Baixa temperatura para respostas mais consistentes
      response_format: { type: 'json_object' },
    })

    const timeoutPromise = new Promise<null>((resolve) => {
      setTimeout(() => resolve(null), timeout)
    })

    const response = await Promise.race([classificationPromise, timeoutPromise])

    if (!response) {
      console.log('‚è±Ô∏è LLM classification timeout:', { timeout })
      return null
    }

    const content = response.choices[0]?.message?.content
    if (!content) {
      console.log('‚ö†Ô∏è Empty response from LLM')
      return null
    }

    // Parsear resposta JSON
    let llmResult: LLMIntentResponse
    try {
      llmResult = JSON.parse(content)
    } catch (parseError) {
      // Tentar extrair JSON do texto (caso venha com markdown ou texto adicional)
      const jsonMatch = content.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        llmResult = JSON.parse(jsonMatch[0])
      } else {
        console.error('‚ùå Failed to parse LLM response as JSON:', {
          content: content.substring(0, 200),
        })
        return null
      }
    }

    // Validar intent
    const validIntents: IntentType[] = [
      'greeting',
      'help',
      'register_meal',
      'register_exercise',
      'query_balance',
      'query_food_info',
      'daily_summary',
      'summary_week',
      'update_user_data',
      'update_goal',
      'onboarding',
      'unknown',
    ]

    if (!validIntents.includes(llmResult.intent)) {
      console.error('‚ùå Invalid intent from LLM:', llmResult.intent)
      return null
    }

    const result: IntentResult = {
      intent: llmResult.intent,
      confidence: Math.max(0, Math.min(1, llmResult.confidence || 0.8)),
      matchedPattern: 'llm_classification',
    }

    console.log('‚úÖ LLM intent classified:', {
      intent: result.intent,
      confidence: result.confidence,
      reasoning: llmResult.reasoning,
      extractedData: llmResult.extracted_data,
    })

    // Armazenar extracted_data em uma propriedade customizada (se necess√°rio no futuro)
    // Por enquanto, apenas logamos

    return result
  } catch (error: any) {
    console.error('‚ùå Error in LLM intent classification:', {
      error: error.message,
      stack: error.stack,
    })
    return null
  }
}

